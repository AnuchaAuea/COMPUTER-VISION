{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f48ad30",
   "metadata": {},
   "source": [
    "# Lab: Image Augmentation using PyTorch\n",
    "\n",
    "## วัตถุประสงค์การเรียนรู้ (Learning Objectives)\n",
    "1. เข้าใจหลักการและความสำคัญของ Image Augmentation\n",
    "2. สามารถใช้ `torchvision.transforms` สำหรับการ augment รูปภาพ\n",
    "3. เข้าใจ transforms แต่ละประเภทและการประยุกต์ใช้\n",
    "4. สามารถสร้าง Custom Dataset พร้อม Augmentation Pipeline\n",
    "5. ประยุกต์ใช้กับ Dataset จริงจาก Kaggle (Animal Faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecaa8d",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to Image Augmentation\n",
    "\n",
    "**Image Augmentation** คือเทคนิคการสร้างข้อมูลรูปภาพเพิ่มเติมจากรูปภาพต้นฉบับ\n",
    "โดยการแปลงรูปภาพด้วยวิธีการต่างๆ เช่น:\n",
    "- Geometric transformations (flip, rotate, crop, scale)\n",
    "- Color transformations (brightness, contrast, saturation)\n",
    "- Noise injection\n",
    "- และอื่นๆ\n",
    "\n",
    "**ประโยชน์:**\n",
    "- เพิ่มขนาด Dataset โดยไม่ต้องเก็บข้อมูลเพิ่ม\n",
    "- ลด Overfitting\n",
    "- ทำให้ Model มีความ robust มากขึ้น\n",
    "- จำลองสถานการณ์ที่หลากหลายในโลกจริง"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34622710-2f9f-4640-86bf-2bfb31afc000",
   "metadata": {},
   "source": [
    "ใช้งานกับ dataset จริงจาก Kaggle\n",
    "\n",
    "**Dataset:** https://www.kaggle.com/datasets/andrewmvd/animal-faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af7ec30e-2e16-46b9-8cb1-4ddb8a17043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook cleaned.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import IPython\n",
    "import sys\n",
    "\n",
    "def clean_notebook():\n",
    "    IPython.display.clear_output(wait=True)\n",
    "    print(\"Notebook cleaned.\")\n",
    "\n",
    "!uv pip install kagglehub\n",
    "\n",
    "# Clean up the notebook\n",
    "clean_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166a2f6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_PATH = './Taj_Mahal.jpg'\n",
    "DATASET_PATH = None  # Path สำหรับ Animal Faces dataset\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2281a2c",
   "metadata": {},
   "source": [
    "## Part 2: Load and Display Original Image\n",
    "\n",
    "เริ่มต้นด้วยการโหลดรูปภาพ Taj Mahal และแสดงผล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee6c6c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def show_image(image, title=\"Image\"):\n",
    "    \"\"\"Display a single image (PIL or Tensor)\"\"\"\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        # Convert tensor to numpy\n",
    "        if image.dim() == 4:\n",
    "            image = image[0]\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "        image = np.clip(image, 0, 1)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_images_grid(images, titles=None, nrow=4, figsize=(16, 12)):\n",
    "    \"\"\"Display multiple images in a grid\"\"\"\n",
    "    n = len(images)\n",
    "    ncol = min(nrow, n)\n",
    "    nrow_actual = (n + ncol - 1) // ncol\n",
    "    \n",
    "    fig, axes = plt.subplots(nrow_actual, ncol, figsize=figsize)\n",
    "    axes = np.array(axes).flatten() if n > 1 else [axes]\n",
    "    \n",
    "    for i, (ax, img) in enumerate(zip(axes, images)):\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            if img.dim() == 4:\n",
    "                img = img[0]\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            img = np.clip(img, 0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i], fontsize=10)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for j in range(len(images), len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4246adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original image\n",
    "original_image = Image.open(IMG_PATH)\n",
    "print(f\"Image size: {original_image.size}\")\n",
    "print(f\"Image mode: {original_image.mode}\")\n",
    "\n",
    "show_image(original_image, \"Original Taj Mahal Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0609c4f",
   "metadata": {},
   "source": [
    "## Part 3: Basic Transforms\n",
    "\n",
    "### 3.1 Geometric Transforms\n",
    "\n",
    "การแปลงทางเรขาคณิตช่วยให้ model เรียนรู้ที่จะรู้จักวัตถุในตำแหน่งและมุมต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c94b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor first (normalized to [0, 1])\n",
    "to_tensor = T.ToTensor()\n",
    "img_tensor = to_tensor(original_image)\n",
    "print(f\"Tensor shape: {img_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1.1 Horizontal Flip\n",
    "horizontal_flip = T.RandomHorizontalFlip(p=1.0)  # p=1.0 means always flip\n",
    "flipped_h = horizontal_flip(img_tensor)\n",
    "\n",
    "# 3.1.2 Vertical Flip\n",
    "vertical_flip = T.RandomVerticalFlip(p=1.0)\n",
    "flipped_v = vertical_flip(img_tensor)\n",
    "\n",
    "# 3.1.3 Random Rotation\n",
    "rotation = T.RandomRotation(degrees=45)\n",
    "rotated_images = [rotation(img_tensor) for _ in range(4)]\n",
    "\n",
    "# Display results\n",
    "show_images_grid(\n",
    "    [img_tensor, flipped_h, flipped_v],\n",
    "    titles=['Original', 'Horizontal Flip', 'Vertical Flip'],\n",
    "    nrow=3,\n",
    "    figsize=(12, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce56e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rotation variations\n",
    "show_images_grid(\n",
    "    rotated_images,\n",
    "    titles=[f'Rotation {i+1}' for i in range(4)],\n",
    "    nrow=4,\n",
    "    figsize=(14, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ca42a",
   "metadata": {},
   "source": [
    "### 3.2 Cropping Transforms\n",
    "\n",
    "การ crop ช่วยให้ model โฟกัสที่ส่วนต่างๆ ของรูปภาพ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.1 Center Crop\n",
    "center_crop = T.CenterCrop(size=400)\n",
    "cropped_center = center_crop(img_tensor)\n",
    "\n",
    "# 3.2.2 Random Crop\n",
    "random_crop = T.RandomCrop(size=300)\n",
    "cropped_random = [random_crop(img_tensor) for _ in range(4)]\n",
    "\n",
    "# 3.2.3 Random Resized Crop (commonly used in training)\n",
    "resized_crop = T.RandomResizedCrop(size=224, scale=(0.5, 1.0), ratio=(0.8, 1.2))\n",
    "cropped_resized = [resized_crop(img_tensor) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a896a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cropping results\n",
    "show_images_grid(\n",
    "    [img_tensor, cropped_center] + cropped_random,\n",
    "    titles=['Original', 'Center Crop'] + [f'Random Crop {i+1}' for i in range(4)],\n",
    "    nrow=3,\n",
    "    figsize=(12, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ef5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display resized crops\n",
    "show_images_grid(\n",
    "    cropped_resized,\n",
    "    titles=[f'RandomResizedCrop {i+1}' for i in range(4)],\n",
    "    nrow=4,\n",
    "    figsize=(14, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4239b34",
   "metadata": {},
   "source": [
    "### 3.3 Color Transforms\n",
    "\n",
    "การปรับสี/แสงช่วยให้ model ทนทานต่อสภาพแสงที่แตกต่างกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d3490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.1 ColorJitter - Adjust brightness, contrast, saturation, hue\n",
    "color_jitter = T.ColorJitter(\n",
    "    brightness=0.5,   # how much to jitter brightness\n",
    "    contrast=0.5,     # how much to jitter contrast\n",
    "    saturation=0.5,   # how much to jitter saturation\n",
    "    hue=0.2           # how much to jitter hue (between -0.5 and 0.5)\n",
    ")\n",
    "jittered_images = [color_jitter(img_tensor) for _ in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_grid(\n",
    "    [img_tensor] + jittered_images,\n",
    "    titles=['Original'] + [f'ColorJitter {i+1}' for i in range(6)],\n",
    "    nrow=4,\n",
    "    figsize=(14, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee3d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3.2 Grayscale\n",
    "grayscale = T.Grayscale(num_output_channels=3)\n",
    "gray_image = grayscale(img_tensor)\n",
    "\n",
    "# 3.3.3 Random Grayscale (with probability)\n",
    "random_gray = T.RandomGrayscale(p=0.5)\n",
    "\n",
    "# 3.3.4 Gaussian Blur\n",
    "gaussian_blur = T.GaussianBlur(kernel_size=15, sigma=(2.0, 5.0))\n",
    "blurred = gaussian_blur(img_tensor)\n",
    "\n",
    "# 3.3.5 Adjust Sharpness\n",
    "sharpness = T.RandomAdjustSharpness(sharpness_factor=3, p=1.0)\n",
    "sharpened = sharpness(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be129d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_grid(\n",
    "    [img_tensor, gray_image, blurred, sharpened],\n",
    "    titles=['Original', 'Grayscale', 'Gaussian Blur', 'Sharpened'],\n",
    "    nrow=4,\n",
    "    figsize=(14, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f854145c",
   "metadata": {},
   "source": [
    "### 3.4 Advanced Transforms\n",
    "\n",
    "เทคนิค augmentation ขั้นสูงที่ใช้กันใน modern deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.1 Random Erasing (Cutout-like)\n",
    "random_erasing = T.RandomErasing(\n",
    "    p=1.0,\n",
    "    scale=(0.02, 0.33),\n",
    "    ratio=(0.3, 3.3),\n",
    "    value=0  # Fill with black (can also use 'random')\n",
    ")\n",
    "erased_images = [random_erasing(img_tensor.clone()) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a040874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_grid(\n",
    "    erased_images,\n",
    "    titles=[f'Random Erasing {i+1}' for i in range(4)],\n",
    "    nrow=4,\n",
    "    figsize=(14, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.2 Random Perspective Transform\n",
    "perspective = T.RandomPerspective(distortion_scale=0.5, p=1.0)\n",
    "perspective_images = [perspective(img_tensor) for _ in range(4)]\n",
    "\n",
    "show_images_grid(\n",
    "    perspective_images,\n",
    "    titles=[f'Perspective {i+1}' for i in range(4)],\n",
    "    nrow=4,\n",
    "    figsize=(14, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4.3 Random Affine Transform\n",
    "affine = T.RandomAffine(\n",
    "    degrees=30,\n",
    "    translate=(0.2, 0.2),\n",
    "    scale=(0.8, 1.2),\n",
    "    shear=15\n",
    ")\n",
    "affine_images = [affine(img_tensor) for _ in range(4)]\n",
    "\n",
    "show_images_grid(\n",
    "    affine_images,\n",
    "    titles=[f'Affine {i+1}' for i in range(4)],\n",
    "    nrow=4,\n",
    "    figsize=(14, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136d2cdb",
   "metadata": {},
   "source": [
    "## Part 4: Composing Transforms\n",
    "\n",
    "ในการใช้งานจริง เรามักจะรวม transforms หลายๆ ตัวเข้าด้วยกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Transform Pipeline (commonly used)\n",
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(15),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test Transform Pipeline (minimal augmentation)\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8cc7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply training transforms multiple times to see variations\n",
    "augmented_train = []\n",
    "for i in range(8):\n",
    "    aug_img = train_transform(original_image)\n",
    "    # Denormalize for visualization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    aug_img_denorm = aug_img * std + mean\n",
    "    augmented_train.append(aug_img_denorm)\n",
    "\n",
    "show_images_grid(\n",
    "    augmented_train,\n",
    "    titles=[f'Train Aug {i+1}' for i in range(8)],\n",
    "    nrow=4,\n",
    "    figsize=(14, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fbd705",
   "metadata": {},
   "source": [
    "## Part 5: RandAugment และ AutoAugment\n",
    "\n",
    "เทคนิค Augmentation อัตโนมัติที่ได้จากการทำ research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5ea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandAugment - Simple yet effective augmentation strategy\n",
    "randaugment = T.RandAugment(num_ops=2, magnitude=9)\n",
    "\n",
    "# AutoAugment - Policy learned from data (ImageNet policy)\n",
    "autoaugment = T.AutoAugment(policy=T.AutoAugmentPolicy.IMAGENET)\n",
    "\n",
    "# TrivialAugment - Even simpler than RandAugment\n",
    "trivialaugment = T.TrivialAugmentWide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different auto augment strategies\n",
    "pil_image = original_image.copy()\n",
    "\n",
    "rand_aug_images = [T.ToTensor()(randaugment(pil_image)) for _ in range(4)]\n",
    "auto_aug_images = [T.ToTensor()(autoaugment(pil_image.copy())) for _ in range(4)]\n",
    "trivial_aug_images = [T.ToTensor()(trivialaugment(pil_image.copy())) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ef055",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandAugment Results:\")\n",
    "show_images_grid(rand_aug_images, titles=[f'RandAug {i+1}' for i in range(4)], nrow=4, figsize=(14, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e551de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AutoAugment Results:\")\n",
    "show_images_grid(auto_aug_images, titles=[f'AutoAug {i+1}' for i in range(4)], nrow=4, figsize=(14, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0934f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TrivialAugment Results:\")\n",
    "show_images_grid(trivial_aug_images, titles=[f'TrivialAug {i+1}' for i in range(4)], nrow=4, figsize=(14, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c214b5f",
   "metadata": {},
   "source": [
    "## Part 9: Comparison of Augmentation Strategies\n",
    "\n",
    "เปรียบเทียบ strategies ต่างๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different augmentation strategies\n",
    "strategies = {\n",
    "    'No Augmentation': T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor()\n",
    "    ]),\n",
    "    'Basic (Flip + Crop)': T.Compose([\n",
    "        T.RandomResizedCrop(224),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor()\n",
    "    ]),\n",
    "    'Moderate': T.Compose([\n",
    "        T.RandomResizedCrop(224),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "        T.ToTensor()\n",
    "    ]),\n",
    "    'Aggressive': T.Compose([\n",
    "        T.RandomResizedCrop(224, scale=(0.5, 1.0)),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.RandomRotation(30),\n",
    "        T.ColorJitter(0.4, 0.4, 0.4, 0.2),\n",
    "        T.GaussianBlur(5),\n",
    "        T.ToTensor()\n",
    "    ]),\n",
    "    'RandAugment': T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.RandAugment(num_ops=2, magnitude=9),\n",
    "        T.ToTensor()\n",
    "    ]),\n",
    "    'AutoAugment': T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.AutoAugment(T.AutoAugmentPolicy.IMAGENET),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1adbc3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Apply all strategies to the image\n",
    "comparison_images = []\n",
    "comparison_titles = []\n",
    "\n",
    "for name, transform in strategies.items():\n",
    "    img = transform(original_image)\n",
    "    comparison_images.append(img)\n",
    "    comparison_titles.append(name)\n",
    "\n",
    "show_images_grid(comparison_images, titles=comparison_titles, nrow=3, figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac8077",
   "metadata": {},
   "source": [
    "## Part 10: Custom Transform Function\n",
    "\n",
    "สร้าง custom transform ของตัวเอง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17929d5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise:\n",
    "    \"\"\"Add Gaussian noise to image\"\"\"\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        noise = torch.randn_like(tensor) * self.std + self.mean\n",
    "        return torch.clamp(tensor + noise, 0., 1.)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(mean={self.mean}, std={self.std})'\n",
    "\n",
    "class MixChannels:\n",
    "    \"\"\"Randomly mix color channels\"\"\"\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        if random.random() < self.p:\n",
    "            # Random permutation of channels\n",
    "            perm = torch.randperm(3)\n",
    "            return tensor[perm, :, :]\n",
    "        return tensor\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(p={self.p})'\n",
    "\n",
    "class RandomCutout:\n",
    "    \"\"\"Apply multiple random cutouts\"\"\"\n",
    "    def __init__(self, n_holes=4, size=32):\n",
    "        self.n_holes = n_holes\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        h, w = tensor.shape[1], tensor.shape[2]\n",
    "        mask = torch.ones_like(tensor)\n",
    "        \n",
    "        for _ in range(self.n_holes):\n",
    "            y = random.randint(0, h - self.size)\n",
    "            x = random.randint(0, w - self.size)\n",
    "            mask[:, y:y+self.size, x:x+self.size] = 0\n",
    "        \n",
    "        return tensor * mask\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}(n_holes={self.n_holes}, size={self.size})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test custom transforms\n",
    "custom_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "img_for_custom = custom_transform(original_image)\n",
    "\n",
    "# Apply custom transforms\n",
    "noisy = AddGaussianNoise(std=0.1)(img_for_custom.clone())\n",
    "mixed = MixChannels(p=1.0)(img_for_custom.clone())\n",
    "cutout = RandomCutout(n_holes=6, size=40)(img_for_custom.clone())\n",
    "\n",
    "show_images_grid(\n",
    "    [img_for_custom, noisy, mixed, cutout],\n",
    "    titles=['Original', 'Gaussian Noise', 'Mixed Channels', 'Multiple Cutouts'],\n",
    "    nrow=4,\n",
    "    figsize=(14, 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d22f6",
   "metadata": {},
   "source": [
    "## Part 12: Summary และ Best Practices\n",
    "\n",
    "### Summary of Transforms\n",
    "\n",
    "| Transform | Use Case | Parameters |\n",
    "|-----------|----------|------------|\n",
    "| RandomHorizontalFlip | Always (most images) | p=0.5 |\n",
    "| RandomResizedCrop | Training | size, scale, ratio |\n",
    "| ColorJitter | Handle lighting variations | brightness, contrast, saturation, hue |\n",
    "| RandomRotation | Objects at different angles | degrees |\n",
    "| GaussianBlur | Reduce noise sensitivity | kernel_size, sigma |\n",
    "| RandAugment | General purpose | num_ops, magnitude |\n",
    "| RandomErasing | Occlusion robustness | p, scale, ratio |\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Start Simple**: Begin with basic augmentations (flip, crop) then add more\n",
    "2. **Match Domain**: Choose augmentations relevant to your use case\n",
    "3. **Don't Overdo**: Too much augmentation can hurt performance\n",
    "4. **Validate Separately**: Never augment validation/test data (except resize/crop)\n",
    "5. **Use AutoAugment/RandAugment**: Good defaults for many tasks\n",
    "6. **Monitor Training**: Watch for signs of under/over-augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48817fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comprehensive pipeline example\n",
    "final_train_transform = T.Compose([\n",
    "    # Spatial transforms\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomRotation(15),\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    \n",
    "    # Color transforms\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.RandomGrayscale(p=0.05),\n",
    "    \n",
    "    # Blur\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
    "    \n",
    "    # Convert to tensor and normalize\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    \n",
    "    # Regularization\n",
    "    T.RandomErasing(p=0.1, scale=(0.02, 0.2))\n",
    "])\n",
    "\n",
    "print(\"Final comprehensive training pipeline created!\")\n",
    "print(\"\\nTransform chain:\")\n",
    "for i, t in enumerate(final_train_transform.transforms):\n",
    "    print(f\"  {i+1}. {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29c1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply final transform\n",
    "final_samples = []\n",
    "for _ in range(8):\n",
    "    aug = final_train_transform(original_image)\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    final_samples.append(aug * std + mean)\n",
    "\n",
    "print(\"\\nFinal Pipeline Results:\")\n",
    "show_images_grid(final_samples, titles=[f'Sample {i+1}' for i in range(8)], nrow=4, figsize=(14, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5380b",
   "metadata": {},
   "source": [
    "## แบบฝึกหัด (Exercises)\n",
    "\n",
    "1. **Exercise 1**: สร้าง transform pipeline สำหรับ medical image classification \n",
    "   (hint: ระวังการ flip และ rotation ที่อาจไม่เหมาะสม)\n",
    "\n",
    "2. **Exercise 2**: เปรียบเทียบ performance ของ model ที่ train ด้วย:\n",
    "   - No augmentation\n",
    "   - Basic augmentation\n",
    "   - RandAugment\n",
    "\n",
    "3. **Exercise 3**: สร้าง custom transform ที่:\n",
    "   - เพิ่ม salt-and-pepper noise\n",
    "   - ทำ channel shuffle\n",
    "   - สร้าง mosaic augmentation\n",
    "\n",
    "4. **Exercise 4**: Download Animal Faces dataset และ:\n",
    "   - วิเคราะห์ class distribution\n",
    "   - สร้าง augmentation pipeline ที่เหมาะสม\n",
    "   - Train simple classifier และวัดผล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Lab: Image Augmentation using PyTorch - Complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nKey Takeaways:\")\n",
    "print(\"• Image augmentation helps reduce overfitting\")\n",
    "print(\"• torchvision.transforms provides comprehensive tools\")\n",
    "print(\"• Different tasks need different augmentation strategies\")\n",
    "print(\"• RandAugment/AutoAugment are good starting points\")\n",
    "print(\"• Always keep validation data unaugmented\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "auto:percent,ipynb",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python (MLOps VEnv)",
   "language": "python",
   "name": "mlops-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
